% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NestRRR.cv.select.r
\name{NestRRR.cv.select}
\alias{NestRRR.cv.select}
\title{Select ranks with cross validation}
\usage{
NestRRR.cv.select(Y, X, nfold = 10, norder = NULL, Ag0 = NULL, Bg0 = NULL,
                  jx, jy, p, d, n,
                  maxiter = 300, conv = 1e-4, quietly = FALSE,
                  method = c('RRR','RRS')[1], lambda=0,
                  dimred = c(TRUE,TRUE,TRUE),
                  rankfix = NULL, xrankfix = NULL, yrankfix = NULL)
}
\arguments{
\item{Y}{response matrix of dimension n-by-jy*d.}

\item{X}{design matrix of dimension n-by-jx*p.}

\item{nfold}{the number of folds used in cross validation. Default is 10.}

\item{norder}{a vector of length n that assigns samples to multiple folds for cross validation.}

\item{Ag0}{an initial estimator of matrix U. If NULL then generate it
by \code{\link{NestRRRini}}. Default is NULL.}

\item{Bg0}{an initial estimator of matrix V, if NULL then generate it
by \code{\link{NestRRRini}}. Default is NULL.}

\item{jx}{the number of basis functions to expand the functional predictor.}

\item{jy}{the number of basis functions to expand the functional response.}

\item{p}{the number of predictors.}

\item{d}{the number of responses.}

\item{n}{sample size.}

\item{maxiter}{the maximum iteration number of the
blockwise coordinate descent algorithm. Default is 300.}

\item{conv}{the tolerance level used to control the convergence of the
blockwise coordinate descent algorithm. Default is 1e-4.}

\item{quietly}{a logical value with two options. FALSE (default): show the
rank selection process; TRUE: do not show the process.}

\item{method}{'RRR' (default): no additional ridge penalty; 'RRS': add an
additional ridge penalty.}

\item{lambda}{the tuning parameter to control the amount of ridge
    penalization. It is only used when \code{method = 'RRS'}.
    Default is 0.
including BIC, BICP, AIC, GCV.}

\item{dimred}{a vector of logical values to decide whether to use cross validation
do rank selection on certain dimensions. TRUE (default): yes; FALSE: no.
If \code{dimred[1]=FALSE}, r is provided by \code{rankfix}
or \eqn{min(jy*d, rank(X))};
If \code{dimred[2]=FALSE}, rx equals to \code{xrankfix} or p; If \code{dimred[3]=FALSE},
ry equals to \code{yrankfix} or d. Default is \code{c(TRUE,TRUE,TRUE)}.}

\item{rankfix}{a user-provided value of r when \code{dimred[1]=FALSE}. Default is NULL
which leads to \eqn{r=min(jy*d,rank(X))}.}

\item{xrankfix}{a user-provided value of rx when \code{dimred[2]=FALSE}. Default is NULL
which leads to \code{rx=p}.}

\item{yrankfix}{a user-provided value of ry when \code{dimred[3]=FALSE}. Default is NULL
which leads to \code{ry=d}.}
}
\value{
The function returns a list:
  \item{Ag}{the estimated U.}
  \item{Bg}{the estimated V.}
  \item{Al}{the estimated A.}
  \item{Bl}{the estimated B.}
  \item{C}{the estimated coefficient matrix C.}
  \item{df}{the estimated degrees of freedom of the selected model.}
  \item{sse}{the sum of squared errors of the selected model.}
  \item{ic}{a vector containing values of BIC, BICP, AIC, GCV of the selected model.}
  \item{rx_path}{a matrix displays the path of selecting rx with cross validation.}
  \item{ry_path}{a matrix displays the path of selecting ry with cross validation.}
  \item{r_path}{a matrix displays the path of selecting r with cross validation.}
  \item{iter}{the number of iterations needed to converge in the selected model.}
  \item{rank}{the estimated r.}
  \item{rx}{the estimated rx.}
  \item{ry}{the estimated ry.}
}
\description{
This function selects the optimal ranks \code{(r, rx, ry)} using a cross
validation procedure. The blockwise coordinate descent algorithm is used to fit
the model with any combinations of \code{(r, rx, ry)}.
}
\details{
A three-dimensional grid search procedure of the rank
values is performed, and the best model is chosen as the one with the
smallest prediction error. Instead of a nested rank selection method, we apply a
one-at-a-time selection approach. We first set \eqn{rx = p, ry = d}, and
select the best local rank \eqn{\hat r} among the models with
\eqn{1 \le r \le min(rank(X), jy*d)}. We then fix the local rank at
\eqn{\hat r} and repeat a similar procedure to determine \eqn{\hat rx}
and \eqn{\hat ry}, one at a time. Finally, with fixed \eqn{\hat rx} and \eqn{\hat ry},
we refine the estimation of r.
}
\examples{
library(NRRR)
set.seed(1)
# Simulation setting 1 in NRRR paper
simDat <- nrrr.sim(n=100,ns=60,nt=60,r=5,rx=3,ry=3,
                   jx=8,jy=8,p=10,d=10,s2n=1,rho_X=0.5,
                   rho_E=0,Sigma="CorrAR")
fit_init <- with(simDat, NestRRR.cv.select(Yest,Xest,nfold=10,norder=NULL,
                              Ag0=NULL,Bg0=NULL,
                              jx=8,jy=8,p=10,d=10,n=100,
                              maxiter=300,conv=1e-4,quietly=FALSE,
                              method=c('RRR','RRS')[1],lambda=0,
                              dimred = c(TRUE,TRUE,TRUE),
                              rankfix=NULL,xrankfix=NULL,yrankfix=NULL))
}
\references{
Liu, X., Ma, S., & Chen, K. (2020).
Multivariate Functional Regression via Nested Reduced-Rank Regularization.
arXiv: Methodology.
}
