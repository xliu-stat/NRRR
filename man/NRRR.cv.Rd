% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NestRRR.cv.select.r
\name{NRRR.cv}
\alias{NRRR.cv}
\title{Select ranks with cross validation}
\usage{
NRRR.cv(Y, X, nfold = 10, norder = NULL, Ag0 = NULL, Bg0 = NULL,
        jx, jy, p, d, n, maxiter = 300, conv = 1e-4,
        method = c('RRR','RRS')[1], lambda=0,
        dimred = c(TRUE,TRUE,TRUE), rankfix = NULL, xrankfix = NULL,
        yrankfix = NULL, lang=c('R','Rcpp')[1])
}
\arguments{
\item{Y}{response matrix of dimension n-by-jy*d.}

\item{X}{design matrix of dimension n-by-jx*p.}

\item{nfold}{the number of folds used in cross validation. Default is 10.}

\item{norder}{a vector of length n that assigns samples to multiple folds for cross validation.}

\item{Ag0}{an initial estimator of matrix U. If \code{Ag0 = NULL} then generate it
by \code{\link{NRRR.ini}}. Default is NULL. If \code{lang = 'Rcpp'},
then \code{Ag0} is automatically generated by \code{\link{NRRR.ini}}.}

\item{Bg0}{an initial estimator of matrix V, if \code{Bg0 = NULL} then generate it
by \code{\link{NRRR.ini}}. Default is NULL. If \code{lang = 'Rcpp'},
then \code{Bg0} is automatically generated by \code{\link{NRRR.ini}}.}

\item{jx}{number of basis functions to expand the functional predictor.}

\item{jy}{number of basis functions to expand the functional response.}

\item{p}{number of predictors.}

\item{d}{number of responses.}

\item{n}{sample size.}

\item{maxiter}{the maximum iteration number of the
blockwise coordinate descent algorithm. Default is 300.}

\item{conv}{the tolerance level used to control the convergence of the
blockwise coordinate descent algorithm. Default is 1e-4.}

\item{method}{'RRR' (default): no additional ridge penalty; 'RRS': add an
additional ridge penalty.}

\item{lambda}{the tuning parameter to control the amount of ridge
penalization. It is only used when \code{method = 'RRS'}.
Default is 0.}

\item{dimred}{a vector of logical values to decide whether to use cross validation
do rank selection on certain dimensions. TRUE means the rank is selected
by cross validation.
If \code{dimred[1] = FALSE}, r is provided by \code{rankfix}
or \eqn{min(jy*d, rank(X))};
If \code{dimred[2] = FALSE}, rx equals to \code{xrankfix} or p; If \code{dimred[3] = FALSE},
ry equals to \code{yrankfix} or d. Default is \code{c(TRUE, TRUE, TRUE)}.}

\item{rankfix}{a user-provided value of r when \code{dimred[1] = FALSE}. Default is NULL
which leads to \eqn{r = min(jy*d, rank(X))}.}

\item{xrankfix}{a user-provided value of rx when \code{dimred[2] = FALSE}. Default is NULL
which leads to \code{rx = p}.}

\item{yrankfix}{a user-provided value of ry when \code{dimred[3] = FALSE}. Default is NULL
which leads to \code{ry = d}.}

\item{lang}{'R' (default): the R version function is used; 'Rcpp': the Rcpp
version function is used.}
}
\value{
The function returns a list:
  \item{Ag}{the estimated U.}
  \item{Bg}{the estimated V.}
  \item{Al}{the estimated A.}
  \item{Bl}{the estimated B.}
  \item{C}{the estimated coefficient matrix C.}
  \item{df}{the estimated degrees of freedom of the selected model.}
  \item{sse}{the sum of squared errors of the selected model.}
  \item{ic}{a vector containing values of BIC, BICP, AIC, GCV of the selected model.}
  \item{rx_path}{a matrix displays the path of selecting rx with cross validation.}
  \item{ry_path}{a matrix displays the path of selecting ry with cross validation.}
  \item{r_path}{a matrix displays the path of selecting r with cross validation.}
  \item{rank}{the estimated r.}
  \item{rx}{the estimated rx.}
  \item{ry}{the estimated ry.}
}
\description{
This function selects the optimal ranks \code{(r, rx, ry)} using a cross
validation procedure. The blockwise coordinate descent algorithm is used to fit
the model with any combinations of \code{(r, rx, ry)}.
}
\details{
A three-dimensional grid search procedure of the rank
values is performed, and the best model is chosen as the one with the
smallest prediction error. Instead of a nested rank selection method, we apply a
one-at-a-time selection approach. We first set \eqn{rx = p, ry = d}, and
select the best local rank \eqn{\hat r} among the models with
\eqn{1 \le r \le min(rank(X), jy*d)}. We then fix the local rank at
\eqn{\hat r} and repeat a similar procedure to determine \eqn{\hat rx}
and \eqn{\hat ry}, one at a time. Finally, with fixed \eqn{\hat rx} and \eqn{\hat ry},
we refine the estimation of r.
}
\examples{
library(NRRR)
set.seed(1)
# Simulation setting 1 in NRRR paper
simDat <- NRRR.sim(n = 100, ns = 60, nt = 60, r = 5, rx = 3, ry = 3,
                   jx = 8, jy = 8, p = 10, d = 10, s2n = 1,
                   rho_X = 0.5, rho_E = 0, Sigma = "CorrAR")
# using R function
fit_R <- with(simDat, NRRR.cv(Yest, Xest, nfold = 10, norder = NULL,
              Ag0 = NULL, Bg0 = NULL, jx = 8, jy = 8, p = 10, d = 10,
              n = 100, maxiter = 300, conv = 1e-4,
              method = c("RRR", "RRS")[1], lambda = 0,
              dimred = c(TRUE, TRUE, TRUE), rankfix = NULL,
              xrankfix = NULL, yrankfix = NULL, lang=c('R','Rcpp')[1]))
# using Rcpp function
fit_Rcpp <- with(simDat, NRRR.cv(Yest, Xest, nfold = 10, norder = NULL,
                 Ag0 = NULL, Bg0 = NULL, jx = 8, jy = 8, p = 10,
                 d = 10, n = 100, maxiter = 300, conv = 1e-4,
                 method = c("RRR", "RRS")[1], lambda = 0,
                 dimred = c(TRUE, TRUE, TRUE), rankfix = NULL,
                 xrankfix = NULL, yrankfix = NULL, lang=c('R','Rcpp')[2]))
}
\references{
Liu, X., Ma, S., & Chen, K. (2020).
Multivariate Functional Regression via Nested Reduced-Rank Regularization.
arXiv: Methodology.
}
